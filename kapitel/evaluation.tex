\section{Evaluation}

In diesem Kapitel wird die entwickelte Middleware evaluiert und die beiden Backend-Ansätze (Excel vs. OData-Services) anhand definierter Kriterien verglichen. Die Evaluation orientiert sich an etablierten Methoden der empirischen Softwaretechnik \citep{wohlin2012} und bewertet sowohl die Anforderungserfüllung als auch qualitative Aspekte der Architektur.

\subsection{Vergleichskriterien}

Für den Vergleich der Backend-Ansätze werden sechs Kriterien herangezogen, die sich an den Qualitätsmerkmalen des ISO/IEC 25010 Standards orientieren \citep{bass2021}. Die Kriterien decken sowohl technische als auch organisatorische Aspekte ab:

Der \textbf{Implementierungsaufwand} bemisst den Aufwand für die initiale Entwicklung des jeweiligen Adapters. Die \textbf{Wartbarkeit} bewertet, wie aufwändig Änderungen und Fehlerbehebungen im laufenden Betrieb sind. Die \textbf{Erweiterbarkeit} beschreibt, wie einfach neue Funktionen (z.\,B. weitere Entitäten oder Metriken) hinzugefügt werden können. Die \textbf{Performance} bezieht sich auf Antwortzeiten und Durchsatz unter realistischen Bedingungen. Die \textbf{Datenkonsistenz} bewertet die Zuverlässigkeit und Aktualität der bereitgestellten Daten. Die \textbf{Austauschbarkeit} misst den Aufwand für einen vollständigen Backend-Wechsel -- das zentrale Kriterium im Kontext der Forschungsfrage.

\subsection{Vergleich: Excel-Backend vs. OData-Services}

Tabelle~\ref{tab:vergleich} stellt die beiden Backend-Ansätze gegenüber. Der Vergleich zeigt, dass die Ansätze komplementäre Stärken aufweisen: Das Excel-Backend punktet mit geringem Setup-Aufwand, Offline-Fähigkeit und einer niedrigen Lernkurve für Endnutzer, die bereits mit Excel vertraut sind. Das OData-Backend bietet hingegen Echtzeitdaten, Transaktionssicherheit und bessere Skalierbarkeit. Die Middleware-Architektur ermöglicht es, zunächst die Vorteile des Excel-Backends zu nutzen und später bei Bedarf auf OData-Services zu migrieren, ohne das Frontend anzupassen.

\begin{table}[H]
\centering
\caption{Vergleich der Backend-Ansätze}
\label{tab:vergleich}
\begin{tabularx}{\textwidth}{l>{\raggedright\arraybackslash}X>{\raggedright\arraybackslash}X}
\toprule
\textbf{Kriterium} & \textbf{Excel/SharePoint} & \textbf{OData Services} \\
\midrule
Setup-Aufwand & Gering -- Excel bereits vorhanden & Mittel -- Service-Konfiguration nötig \\
\midrule
Echtzeitdaten & Nein -- Power Query muss manuell aktualisiert werden & Ja -- direkte Abfrage \\
\midrule
Transaktionen & Nein -- keine ACID-Garantien & Ja -- Datenbank-Transaktionen \\
\midrule
Skalierbarkeit & Begrenzt -- Dateigröße limitiert & Hoch -- Datenbank skaliert \\
\midrule
Offline-Fähigkeit & Ja -- Excel lokal verfügbar & Nein -- Service muss erreichbar sein \\
\midrule
Lernkurve Endnutzer & Gering -- Excel bekannt & Höher -- neue Oberfläche \\
\bottomrule
\end{tabularx}
\end{table}

\subsection{Bewertung der Anforderungserfüllung}

Die in Kapitel~3 definierten Anforderungen werden im Folgenden gegen den Implementierungsstand geprüft. Dabei wird zwischen vollständiger Erfüllung, teilweiser Erfüllung und Nichterfüllung unterschieden.

\subsubsection{Funktionale Anforderungen}

Tabelle~\ref{tab:fa-erfuellung} zeigt, dass sechs von sieben funktionalen Anforderungen vollständig erfüllt sind. Die einzige Einschränkung betrifft FA-06 (SharePoint-Anbindung): Der Excel-Parser kann Dateien lokal lesen und verarbeiten, jedoch fehlen zum Zeitpunkt der Abgabe die SharePoint-Berechtigungen für den produktiven Zugriff über Microsoft Graph. Die technische Implementierung (OAuth-Flow, Datei-Download) ist vorbereitet, konnte aber nicht mit dem Produktiv-SharePoint getestet werden.

\begin{table}[H]
\centering
\caption{Erfüllung der funktionalen Anforderungen}
\label{tab:fa-erfuellung}
\begin{tabularx}{\textwidth}{l>{\raggedright\arraybackslash}Xc}
\toprule
\textbf{ID} & \textbf{Anforderung} & \textbf{Status} \\
\midrule
FA-01 & Budget-Metriken pro Team berechnen & Erfüllt \\
FA-02 & Budget-Metriken pro \gls{psp} berechnen & Erfüllt \\
FA-03 & \gls{crud} für \gls{psp}-Zuordnungen & Erfüllt \\
FA-04 & Session-basiertes Projekt-Management & Erfüllt \\
FA-05 & Team-Mismatch-Warnungen & Erfüllt \\
FA-06 & Excel-Daten von SharePoint lesen & Teilweise* \\
FA-07 & Änderungen in Excel schreiben & Erfüllt \\
\bottomrule
\end{tabularx}
\end{table}

*FA-06: Lokales Lesen funktioniert, SharePoint-Berechtigungen noch ausstehend.

\subsubsection{Nicht-funktionale Anforderungen}

Alle nicht-funktionalen Anforderungen sind vollständig erfüllt (Tabelle~\ref{tab:nfa-erfuellung}). Besonders hervorzuheben ist NFA-01 (Backend-Austauschbarkeit): Die Adapter-Architektur ermöglicht nachweislich den Wechsel des Backends, ohne dass die Service-Schicht, die CDS-Definitionen oder das Frontend angepasst werden müssen. Die OData-Kompatibilität (NFA-02) wird durch SAP \gls{cap} automatisch sichergestellt, was auch die Fiori-Eignung (NFA-04) impliziert.

\begin{table}[H]
\centering
\caption{Erfüllung der nicht-funktionalen Anforderungen}
\label{tab:nfa-erfuellung}
\begin{tabularx}{\textwidth}{l>{\raggedright\arraybackslash}Xc}
\toprule
\textbf{ID} & \textbf{Anforderung} & \textbf{Status} \\
\midrule
NFA-01 & Backend austauschbar & Erfüllt \\
NFA-02 & \gls{odata} v4-kompatibel & Erfüllt \\
NFA-03 & Auf SAP \gls{btp} deploybar & Erfüllt \\
NFA-04 & Für Fiori-Frontend geeignet & Erfüllt \\
NFA-05 & Ohne lokale Datenbank & Erfüllt \\
\bottomrule
\end{tabularx}
\end{table}

\subsection{Bewertung der Austauschbarkeit}

Die zentrale Forschungsfrage zielt auf die Austauschbarkeit des Backends ab. Um diese zu bewerten, wird analysiert, welche Komponenten bei einem Backend-Wechsel unverändert bleiben, welche angepasst werden müssen und welcher Aufwand dafür anfällt.

\subsubsection{Durch das Adapter-Pattern geschützte Komponenten}

Durch das Adapter-Pattern bleiben zentrale Komponenten bei einem Backend-Wechsel unverändert. Die \gls{cds} Service-Definition (\texttt{budget-service.cds}) definiert die \gls{api}-Schnittstelle unabhängig von der Datenquelle und erfordert keine Anpassungen. Die Budget-Berechnungslogik (\texttt{budget-calculations.js}) arbeitet ausschließlich auf den abstrakten Datenstrukturen des Adapters -- sie hat keine Kenntnis davon, ob die Daten aus Excel oder einem OData-Service stammen. Ebenso bleiben das Session-Management, die Fehlerbehandlung, die \gls{api}-Dokumentation sowie sämtliche 113 automatisierten Tests für die Service-Schicht unverändert. Insgesamt sind damit über 80\,\% der Codebasis vom Backend-Wechsel nicht betroffen.

\subsubsection{Bei Backend-Wechsel zu ändernde Komponenten}

Bei einem Backend-Wechsel muss ein neuer OData-Adapter implementiert werden, der das gleiche DataAdapter-Interface erfüllt wie der bestehende Excel-Adapter. Dieser Adapter würde HTTP-Requests an die \gls{calm}-\gls{api} senden, die Antworten auf das interne Datenmodell mappen und die Authentifizierung über OAuth 2.0 Client Credentials abwickeln. Zusätzlich muss die \texttt{loadData()}-Funktion in der Service-Schicht so konfiguriert werden, dass sie den neuen Adapter anstelle des Excel-Adapters aufruft. Der Write-Back für \gls{psp}-Zuordnungen müsste ebenfalls auf die \gls{calm}-\gls{api} umgestellt werden, wobei der PSP-Override-Mechanismus entfallen kann, da Änderungen direkt im Backend persistiert würden.

\subsubsection{Geschätzter Aufwand für Backend-Wechsel}

Basierend auf der Implementierungserfahrung lässt sich der Aufwand für einen Backend-Wechsel abschätzen:

\begin{table}[H]
\centering
\caption{Geschätzter Aufwand für Backend-Wechsel zu OData}
\label{tab:aufwand}
\begin{tabularx}{\textwidth}{>{\raggedright\arraybackslash}Xlc}
\toprule
\textbf{Komponente} & \textbf{Aufgabe} & \textbf{Aufwand} \\
\midrule
ODataAdapter & Implementierung analog zu ExcelAdapter & 3--5 PT \\
Authentifizierung & OAuth 2.0 für SAP Cloud ALM & 1--2 PT \\
Mapping & Anpassung der Datenstrukturen & 2--3 PT \\
Testing & Integration \& Regressionstests & 2--3 PT \\
\midrule
\textbf{Gesamt} & & \textbf{8--13 PT} \\
\bottomrule
\end{tabularx}
\end{table}

Die Service-Schicht, CDS-Definitionen und das Frontend bleiben dabei unverändert (siehe Tabelle~\ref{tab:aufwand}) -- ein Beleg für die Wirksamkeit des Adapter-Patterns.

\subsection{Performance-Analyse}

Die Performance wurde auf der deployed Instanz (SAP BTP Cloud Foundry, 256 MB RAM) gemessen. Jeder Endpoint wurde 10-mal aufgerufen und der Median der Antwortzeiten ermittelt.

\begin{table}[H]
\centering
\caption{Antwortzeiten der API-Endpunkte}
\label{tab:performance}
\begin{tabularx}{\textwidth}{Xccc}
\toprule
\textbf{Endpoint} & \textbf{Datenmenge} & \textbf{Median} & \textbf{Max} \\
\midrule
GET /BudgetOverview & 14 Teams & 180 ms & 250 ms \\
GET /UserStories & 251 Stories & 320 ms & 480 ms \\
GET /TimeBookings & 3555 Buchungen & 890 ms & 1.200 ms \\
GET /PSPElements & 113 Elemente & 150 ms & 210 ms \\
POST /startSession & -- & 45 ms & 80 ms \\
\bottomrule
\end{tabularx}
\end{table}

\textbf{Bewertung}: Die gemessenen Antwortzeiten liegen größtenteils unter 1 Sekunde, was nach etablierten Usability-Richtlinien als angemessen einzustufen ist -- Antwortzeiten unter 1 Sekunde werden von Nutzern als flüssig wahrgenommen, während Zeiten über 10 Sekunden zu Abbrüchen führen \citep{nielsen1993}. Moderne Web-Performance-Metriken empfehlen Interaktionszeiten unter 200\,ms für eine optimale Benutzererfahrung \citep{google2020}. Der überwiegende Anteil der Latenz ist auf das Parsen der Excel-Datei zurückzuführen. Bei einem Wechsel zu OData-Services ist mit kürzeren Antwortzeiten zu rechnen, da keine Dateitransformation erforderlich ist.

\subsection{Testszenarien}

Neben den 113 automatisierten Tests (vgl. Abschnitt~5.10) wurde die Middleware anhand manuell definierter Testszenarien validiert, die das Zusammenspiel aller Komponenten auf der deployed Instanz prüfen. Die Szenarien decken sowohl den Normalfall als auch Grenzfälle und Fehlerszenarien ab.

\subsubsection{Funktionale Tests}

Tabelle~\ref{tab:functional-tests} zeigt die zehn funktionalen Testszenarien, die alle relevanten Use Cases abdecken. Jedes Szenario wurde auf der deployed BTP-Instanz mit realen Testdaten durchgeführt.

\begin{table}[H]
\centering
\caption{Funktionale Testszenarien}
\label{tab:functional-tests}
\begin{tabularx}{\textwidth}{cl>{\raggedright\arraybackslash}Xc}
\toprule
\textbf{ID} & \textbf{Szenario} & \textbf{Erwartetes Ergebnis} & \textbf{Status} \\
\midrule
T-01 & Session starten & Session-ID wird zurückgegeben & \checkmark \\
T-02 & Ungültige Session & 401 Unauthorized & \checkmark \\
T-03 & Budget pro Team abrufen & 14 Teams mit korrekten Summen & \checkmark \\
T-04 & Budget pro PSP abrufen & 113 PSP-Elemente & \checkmark \\
T-05 & OData \$filter anwenden & Gefilterte Ergebnisse & \checkmark \\
T-06 & OData \$top/\$skip & Paginierung funktioniert & \checkmark \\
T-07 & PSP-Zuordnung erstellen & Eintrag in Excel geschrieben & \checkmark \\
T-08 & PSP-Zuordnung löschen & Eintrag aus Excel entfernt & \checkmark \\
T-09 & Team-Mismatch erkennen & Warnung wird generiert & \checkmark \\
T-10 & Projekt wechseln & Neue Session für anderes Projekt & \checkmark \\
\bottomrule
\end{tabularx}
\end{table}

\subsubsection{Grenzwert-Tests}

Die Grenzwert-Tests (Tabelle~\ref{tab:boundary-tests}) prüfen das Verhalten der Middleware bei ungewöhnlichen oder fehlerhaften Eingaben. Sie stellen sicher, dass die in Abschnitt~4.9 definierte Fehlerbehandlung korrekt greift und die Middleware auch bei Randfällen konsistente Antworten liefert.

\begin{table}[H]
\centering
\caption{Grenzwert-Testszenarien}
\label{tab:boundary-tests}
\begin{tabularx}{\textwidth}{l>{\raggedright\arraybackslash}Xc}
\toprule
\textbf{Szenario} & \textbf{Erwartetes Verhalten} & \textbf{Status} \\
\midrule
Leere Excel-Datei & Leere Arrays werden zurückgegeben & \checkmark \\
User Story ohne PSP & pspElement = \enquote{unassigned}, nicht in ETC & \checkmark \\
PSP ohne Budget & budgetPT = 0 & \checkmark \\
Doppelte PSP-Zuordnung & 409 Conflict & \checkmark \\
Session nach 8h & 401 Session abgelaufen & \checkmark \\
Ungültiges Projekt & 404 Not Found & \checkmark \\
\bottomrule
\end{tabularx}
\end{table}

\subsection{SWOT-Analyse der Architektur}

Eine SWOT-Analyse (Strengths, Weaknesses, Opportunities, Threats) ist ein etabliertes Instrument der strategischen Planung, das sowohl interne Faktoren (Stärken, Schwächen) als auch externe Faktoren (Chancen, Risiken) berücksichtigt \citep{helms2010}. Die folgende Analyse fasst die Bewertung der gewählten Architektur zusammen:

\begin{table}[H]
\centering
\caption{SWOT-Analyse der BC Middleware Architektur}
\label{tab:swot}
\begin{tabularx}{\textwidth}{|X|X|}
\hline
\textbf{Stärken (Strengths)} & \textbf{Schwächen (Weaknesses)} \\
\hline
\begin{itemize}[leftmargin=*, nosep]
    \item Austauschbares Backend durch Adapter-Pattern
    \item OData-Konformität für Fiori-Integration
    \item Keine zusätzliche Datenbank erforderlich
    \item Einfaches Deployment auf SAP BTP
    \item Excel als vertraute Datenquelle für Anwender
\end{itemize}
&
\begin{itemize}[leftmargin=*, nosep]
    \item Keine Echtzeitdaten (Excel-Refresh nötig)
    \item Sessions nicht persistent
    \item Keine ACID-Transaktionen
    \item Begrenzte Skalierbarkeit bei großen Excel-Dateien
    \item SharePoint-Integration noch nicht produktiv
\end{itemize}
\\
\hline
\textbf{Chancen (Opportunities)} & \textbf{Risiken (Threats)} \\
\hline
\begin{itemize}[leftmargin=*, nosep]
    \item Migration zu SAP Cloud ALM möglich
    \item Erweiterung um weitere Projektcontrolling-Funktionen
    \item Integration mit SAP Analytics Cloud
    \item Wiederverwendung des Patterns für andere Projekte
\end{itemize}
&
\begin{itemize}[leftmargin=*, nosep]
    \item Excel-Datei wird versehentlich beschädigt
    \item Konkurrierende Zugriffe auf Excel
    \item API-Änderungen bei SAP Cloud ALM
    \item Performance bei sehr großen Projekten
\end{itemize}
\\
\hline
\end{tabularx}
\end{table}

\subsection{Lessons Learned}

Aus der Implementierung und dem Betrieb der Middleware ergeben sich mehrere Erkenntnisse.

Das Adapter-Pattern hat sich bewährt: Die strikte Trennung zwischen Service- und Adapter-Schicht erwies sich als praktikabel. Änderungen am Excel-Format erforderten nur Anpassungen im Adapter, nicht in der Geschäftslogik, was die Empfehlungen von \cite{gamma1994} bestätigt.

Das Schreiben in Excel erwies sich als deutlich komplexer als das Lesen. Insbesondere Formeln, Formatierungen und Zellreferenzen müssen erhalten bleiben. Die xlsx-Bibliothek unterstützt dies, erfordert aber detailliertes Verständnis der Excel-Interna.

Die deklarative Service-Definition mit \gls{cds} beschleunigt die Entwicklung erheblich, da Boilerplate-Code reduziert wird und OData-Konformität, Filterung sowie Paginierung automatisch bereitgestellt werden \citep{sap2024cap}.

Das Session-Management im RAM birgt Risiken: Bei Serverneustart gehen Sessions verloren, weshalb für den produktiven Einsatz eine Persistierung etwa über Redis oder eine Datenbank erforderlich wäre \citep{richardson2018}.

Schließlich zeigt sich, dass die Middleware als Integrationsmuster fungiert -- konkret als \enquote{Anti-Corruption Layer} \citep{vernon2013}, der das Frontend vor den Eigenheiten der Excel-Struktur schützt. Dieses Muster ist auch aus den Enterprise Integration Patterns bekannt, wo es als \enquote{Message Translator} beschrieben wird \citep{hohpe2003}.
